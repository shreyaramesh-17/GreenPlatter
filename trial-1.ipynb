{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd9b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn joblib --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675140df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (12000, 9)\n",
      "         Date  DayOfWeek  Guests     Event Weather            Dish  \\\n",
      "0  01-12-2024     Sunday     187       NaN    Cold       Veg Pulao   \n",
      "1  23-11-2024   Saturday     321       NaN   Sunny   Chicken Curry   \n",
      "2  03-01-2024  Wednesday      65       NaN  Cloudy       Veg Pulao   \n",
      "3  20-08-2024    Tuesday      53       NaN   Rainy  Veg Manchurian   \n",
      "4  08-10-2024    Tuesday     338  Festival     Hot   Pasta Alfredo   \n",
      "\n",
      "   Prepared_Qty  Sold_Qty  Waste_Qty  \n",
      "0            37        36          7  \n",
      "1            44        44          3  \n",
      "2            27        23          4  \n",
      "3            38        34          4  \n",
      "4            41        40          7  \n",
      "\n",
      "Cross-Validated Performance on Training (TimeSeriesSplit):\n",
      "MAE: mean=6.83 ± 0.15\n",
      "R² : mean=0.18 ± 0.06\n",
      "\n",
      "Holdout Test Performance (chronological 20%):\n",
      "Mean Absolute Error (MAE): 6.55\n",
      "R² Score: 0.27\n",
      "\n",
      "Sample Predictions:\n",
      "   Actual  Predicted\n",
      "0    47.0  36.551921\n",
      "1    48.0  46.161429\n",
      "2    49.0  37.522347\n",
      "3    50.0  41.573327\n",
      "4    50.0  44.080092\n",
      "5    48.0  40.571919\n",
      "6    50.0  42.050094\n",
      "7    39.0  44.536221\n",
      "8    50.0  47.327203\n",
      "9    39.0  46.338377\n",
      "\n",
      "Pipeline saved as greenplatter_pipeline.joblib\n",
      "Category options saved as greenplatter_categories.json\n"
     ]
    }
   ],
   "source": [
    "# GreenPlatter - Demand Prediction Training Script (Pipeline + CV + Chrono Split)\n",
    "# Author: Your Name\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import joblib\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load Dataset\n",
    "# ----------------------------\n",
    "file_path = \"Expanded_GreenPlatter_12000.csv\"  # ensure file exists in working dir\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Parse date and sort chronologically to avoid leakage\n",
    "if \"Date\" in df.columns:\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Define Features & Target (no manual label encoding)\n",
    "# ----------------------------\n",
    "feature_cols = [\"DayOfWeek\", \"Guests\", \"Event\", \"Weather\", \"Dish\"]\n",
    "target_col = \"Sold_Qty\"\n",
    "\n",
    "# Handle missing categorical values by replacing NaN with string \"Unknown\"\n",
    "for col in [\"DayOfWeek\", \"Event\", \"Weather\", \"Dish\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].astype(float)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Build Pipeline: OneHotEncoder + HistGradientBoostingRegressor\n",
    "# ----------------------------\n",
    "categorical_features = [\"DayOfWeek\", \"Event\", \"Weather\", \"Dish\"]\n",
    "numeric_features = [\"Guests\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
    "        (\"num\", \"passthrough\", numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "regressor = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=None,\n",
    "    max_iter=300,\n",
    "    l2_regularization=0.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", regressor),\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Chronological Train/Test Split (last 20% for test)\n",
    "# ----------------------------\n",
    "num_rows = len(df)\n",
    "split_index = int(num_rows * 0.8)\n",
    "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Cross-validated metrics on training set (TimeSeriesSplit)\n",
    "# ----------------------------\n",
    "ts_cv = TimeSeriesSplit(n_splits=5)\n",
    "mae_scores = -cross_val_score(pipeline, X_train, y_train, cv=ts_cv, scoring=\"neg_mean_absolute_error\", n_jobs=None)\n",
    "r2_scores = cross_val_score(pipeline, X_train, y_train, cv=ts_cv, scoring=\"r2\", n_jobs=None)\n",
    "\n",
    "print(\"\\nCross-Validated Performance on Training (TimeSeriesSplit):\")\n",
    "print(f\"MAE: mean={mae_scores.mean():.2f} ± {mae_scores.std():.2f}\")\n",
    "print(f\"R² : mean={r2_scores.mean():.2f} ± {r2_scores.std():.2f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Fit on training and evaluate on holdout test\n",
    "# ----------------------------\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nHoldout Test Performance (chronological 20%):\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Show Sample Predictions\n",
    "# ----------------------------\n",
    "results = pd.DataFrame({\"Actual\": y_test.values[:10], \"Predicted\": y_pred[:10]})\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(results)\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Persist: Save Pipeline and Category Metadata\n",
    "# ----------------------------\n",
    "joblib.dump(pipeline, \"greenplatter_pipeline.joblib\")\n",
    "print(\"\\nPipeline saved as greenplatter_pipeline.joblib\")\n",
    "\n",
    "# Save original category options for the app UI\n",
    "category_options = {\n",
    "    \"DayOfWeek\": sorted(pd.Series(X[\"DayOfWeek\"]).dropna().unique().tolist()),\n",
    "    \"Event\": sorted(pd.Series(X[\"Event\"]).dropna().unique().tolist()),\n",
    "    \"Weather\": sorted(pd.Series(X[\"Weather\"]).dropna().unique().tolist()),\n",
    "    \"Dish\": sorted(pd.Series(X[\"Dish\"]).dropna().unique().tolist()),\n",
    "}\n",
    "with open(\"greenplatter_categories.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(category_options, f, ensure_ascii=False, indent=2)\n",
    "print(\"Category options saved as greenplatter_categories.json\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
